# Оптимизация запросов

[source](https://postgrespro.ru/education/courses/QPT)

## Содержание

<!-- MarkdownTOC autolink="true" uri_encoding="false" levels="2,3" -->

- [0. Разное](#0-Разное)
    - [0.1 Просмотр этапов выполнения запроса в логах](#01-Просмотр-этапов-выполнения-запроса-в-логах)
    - [0.2 Подготовка запросов и просмотр подготовленных запросов](#02-Подготовка-запросов-и-просмотр-подготовленных-запросов)
    - [0.3 Отображение времени выполнения команд psql \(в т. ч. запросов\)](#03-Отображение-времени-выполнения-команд-psql-в-т-ч-запросов)
    - [0.4 Просмотр структуры таблиц](#04-Просмотр-структуры-таблиц)
    - [0.5 Отключение отдельных узлов выполнения запроса](#05-Отключение-отдельных-узлов-выполнения-запроса)
- [1. Выполнение запросов](#1-Выполнение-запросов)
    - [1.1 Подходы к оптимизации](#11-Подходы-к-оптимизации)
    - [1.2 Этапы выполнения запроса](#12-Этапы-выполнения-запроса)
    - [1.3 Расширенные запросы](#13-Расширенные-запросы)
    - [1.4 Этап планирования](#14-Этап-планирования)
- [2. Последовательное сканирование](#2-Последовательное-сканирование)
    - [2.1 Последовательное сканирование \(Seq Scan\)](#21-Последовательное-сканирование-seq-scan)
    - [2.2 Распараллеливание запросов](#22-Распараллеливание-запросов)
    - [2.3 Параллельное последовательное сканирование \(Parallel Sec Scan\)](#23-Параллельное-последовательное-сканирование-parallel-sec-scan)
    - [2.4 Настройка параллельных запросов](#24-Настройка-параллельных-запросов)
    - [2.5 Примеры анализа](#25-Примеры-анализа)
- [3. Индексное сканирование](#3-Индексное-сканирование)
    - [3.1 Индекс B-tree](#31-Индекс-b-tree)
    - [3.2 Index Scan](#32-index-scan)
    - [3.3 Параллельное индексное сканирование](#33-Параллельное-индексное-сканирование)
    - [3.4 Index Only Scan](#34-index-only-scan)
    - [3.5 Примеры планов](#35-Примеры-планов)
- [4. Сканирование по битовой карте](#4-Сканирование-по-битовой-карте)
    - [4.1 Основы Bitmap Scan](#41-Основы-bitmap-scan)
    - [4.2 Использование памяти](#42-Использование-памяти)
    - [4.3 Parallel Bitmap Scan](#43-parallel-bitmap-scan)
    - [4.4 Пример анализа](#44-Пример-анализа)
    - [4.5 Сравнение способов доступа](#45-Сравнение-способов-доступа)
- [5. Соединение вложенным циклом](#5-Соединение-вложенным-циклом)
    - [5.1 Общие замечания](#51-Общие-замечания)
    - [5.2 Соединение вложенным циклом \(Nested Loop\)](#52-Соединение-вложенным-циклом-nested-loop)
    - [5.3 Пример анализа](#53-Пример-анализа)
- [6. Соединение хешированием \(Hash Join\)](#6-Соединение-хешированием-hash-join)
    - [6.1 Алгоритм соединения](#61-Алгоритм-соединения)
    - [6.2 Использование памяти](#62-Использование-памяти)
    - [6.3 Пример анализа](#63-Пример-анализа)
- [7. Соединение слиянием](#7-Соединение-слиянием)
    - [7.1 Алгоритм](#71-Алгоритм)
    - [7.2 Использование памяти \(для сортировки\)](#72-Использование-памяти-для-сортировки)
    - [7.3 Построение B-tree индекса](#73-Построение-b-tree-индекса)
    - [7.4 Пример](#74-Пример)
- [8. Статистика](#8-Статистика)
    - [8.1 Базовая статистика](#81-Базовая-статистика)
    - [8.2 Гистограмма](#82-Гистограмма)
    - [8.3 Дополнительные поля](#83-Дополнительные-поля)
    - [8.4 Расширенная статистика](#84-Расширенная-статистика)
    - [8.5 Как выполняется сбор статистики](#85-Как-выполняется-сбор-статистики)
- [9. Профилирование](#9-Профилирование)
    - [9.1 Общие подходы](#91-Общие-подходы)
    - [9.2 Профилирование запросов](#92-Профилирование-запросов)
    - [9.3 Профилирование одного запроса](#93-Профилирование-одного-запроса)
- [10 Приемы оптимизации](#10-Приемы-оптимизации)
    - [10.1 Оптимизация параметрами](#101-Оптимизация-параметрами)
    - [10.3 Оптимизация на уровне схемы БД](#103-Оптимизация-на-уровне-схемы-БД)
    - [10.4 Переформулирование запроса](#104-Переформулирование-запроса)

<!-- /MarkdownTOC -->

## 0. Разное

### 0.1 Просмотр этапов выполнения запроса в логах

Устанавливаем параметры

    ALTER SYSTEM SET log_parser_stats = on;
    ALTER SYSTEM SET log_planner_stats = on;
    ALTER SYSTEM SET log_executor_stats = on;
    SELECT pg_reload_conf();

Теперь можно выполнять анализ и смотреть логи

    EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF) SELECT * FROM ticket_flights;

    tail -n 50 /var/log/postgresql/postgresql-10-main.log | egrep 'LOG: |elapsed'

### 0.2 Подготовка запросов и просмотр подготовленных запросов

Создаем:

    PREPARE model(varchar) AS SELECT model FROM aircrafts WHERE aircraft_code = $1;

Все подготовленные хранятся в **pg_prepared_statements** до конца сеанса:

    SELECT * FROM pg_prepared_statements \gx

### 0.3 Отображение времени выполнения команд psql (в т. ч. запросов)

    \timing on

### 0.4 Просмотр структуры таблиц

    \d bookings
                                  Table "bookings.bookings"
        Column    |           Type           | Collation | Nullable | Default 
    --------------+--------------------------+-----------+----------+---------
     book_ref     | character(6)             |           | not null | 
     book_date    | timestamp with time zone |           | not null | 
     total_amount | numeric(10,2)            |           | not null | 
    Indexes:
        "bookings_pkey" PRIMARY KEY, btree (book_ref)
    Referenced by:
        TABLE "tickets" CONSTRAINT "tickets_book_ref_fkey" FOREIGN KEY (book_ref) REFERENCES bookings(book_ref)

### 0.5 Отключение отдельных узлов выполнения запроса

    SET enable_bitmapscan = off;
    SET enable_seqscan = off;

и другие параметры, начинающиеся с `enable_`

По факту не запрещается совсем, а просто сильно увеличивает стоимость узла. Если других вариантов не будет - будет использоваться запрещенный узел.




## 1. Выполнение запросов

### 1.1 Подходы к оптимизации

* Мониторинг нагрузки и подстраивание системы под нее (конфигурационные параметры, настройка ОС и т. п.)
    - глобально влияет на всю систему
* Уменьшение нагрузки
    - основная нагрузка создается запросами
    - можно оптимизировать отдельные запросы, что положительно скажется на всей системе
    

### 1.2 Этапы выполнения запроса

* **Разбор** (parse)
    - синтаксический: проверяется корректность запроса
    - семантический: какие объекты БД требуются, если ли на них права (анализируется например `pg_tables`)
    - результат разбора - дерево
    - можно посмотреть в логах, если включить `debug_print_parse`, но особо не нужно
* **Переписывание** (rewrite)
    - например добавляются тексты запросов вместо представлений
* **Планирование** 
    - планировщик (оптимизатор) перебирает возможные способы выполнения запроса
    - дает оценку выполнения на основе статистики
    - выбирает наиболее оптимальный план
* **Выполнение**
    - по выбранному плану 
    - обход дерева, начиная с нижних узлов
    - каждый узел передает данные верхнему узлу
    - разные типы узлов: выбирают данные из тадлиц, соединяют данные от других узлов, сортируют и т. п.
    
### 1.3 Расширенные запросы

**Подготовленные запросы** и **курсоры**

Подготовленный (параметризованный) запрос:

* клиент передает запрос с параметрами
* сервер выполняет разбор и переписывание и сохраняет результат (дерево) в локальной памяти процесса
* клиент вызывает запрос по имени с значениями параметров
* сервер планирует и выполняет запрос
* экономия на разборе запроса, если несколько раз выполняется в течении сеанса

Если параметров нет, сервер сразу планирует подготовленный запрос и хранит его в памяти.

С параметрами перепланирует запрос ограниченное число раз (5). Если общий план не хуже частных, перестает использовать перепланирование.

Курсоры:

* запрос выполняется по частям
* курсоры хранятся в локальной памяти процесса

### 1.4 Этап планирования

#### 1.4.1 Критерии стоимости плана

Оптимизатор перебирает планы, оценивает их стоимость, выбирает с наименьшей стоимостью.

Для оценки стоимости:

* **селективность** - доля строк, отбираемых условиями
* **кардинальность** - обшее число строк

Нужна статистика. Основные ошибки - если неверно оценена кардинальность (неадекватная статистика)

#### 1.4.2 Оценка кардинальности

Кардинальность как рекурсивный процесс: оцениваем кардинальность дочерних узлов, затем зная тип узла - его кардинальность.

Например сначала оценивается кардинальность узлов доступа к данным (на основе размера таблиц и селективности). Если можем оценить селективность простых условий, селективность сложных (AND, OR) - выводится из простых по формулам:

    sel(a AND b) = sel(a) * sel(b)
    sel(a OR b) = 1 - (1 - sel(a)) * (1 - sel(b))

Затем оценивается кардинальность соединений (см. далее как)

Если возникают ошибки оценки в нижних узлах - нарастают и могут приводить к выбору неверного плана


#### 1.4.3 Оценка стоимости

Также рекурсивный процесс: стоимость дерева = стоимость узла + стоимость поддерева.

Стоимость узла - мат. модель на основе числа обрабатываемых строк. Для каждого типа узла - своя модель.

    Стоимость = стоимость подготовки + стоимость выборки

Некоторые узлы не имеют подготовки. У некоторых всегда она будет (например узел сортировки сначала выбирает данные, затем сортирует)

Стоимость - просто оценка. Выражена в условных единицах. Может не коррелировать с временем выполнения.


#### 1.4.4 Выбор плана

Оптимизатор пытается перебрать все планы (порядок соединений, способы соединений, методы доступа)

Если слишком много вариантов - переключается на генетический алгоритм.

Что такое лучший план:

* для обычных и подготовленных запросов - минимальная общая стоимость (минимальное время получение всего результата)
* для курсоров - минимизируется время получения первых результатов
    - есть параметр `cursor_tuple_fraction` - доля строк для быстрого получения. По умолчанию - 0.1


## 2. Последовательное сканирование

### 2.1 Последовательное сканирование (Seq Scan)

Доступ к данным через последовательное сканирование страниц файла. На странице читаются строки и проверяется их видимость.

При чтении - буферное кольцо, процессы могут присоединятся к чтению.

Эффективно, если нужно читать большую часть таблицы (селективность низкая).

### 2.2 Распараллеливание запросов

Ведущий процесс, выполняющий запрос, порождает несколько рабочих процессов, передавая им часть плана (параллельный план). Рабочие процессы передают результат своей работы в узел `Gather` ведущего процесса.

Если у ведущего процесса есть время, он может также выполнять параллельную часть плана.

### 2.3 Параллельное последовательное сканирование (Parallel Sec Scan)

Страницы таблицы читаются последовательно, но страницы распределяются между несколькими рабочими процессами. Рабочие процессы синхронизированны, что чтение шло в правильном порядке. 

Дает выигрыш, если происходит не только чтение, а еще и обработка страниц (например подсчет агрегация)

### 2.4 Настройка параллельных запросов

Общее число рабочих процессов (не только запросы, но и например репликация) ограничено `max_worker_processes` - 8 по умолчанию.

Из этих процессов, количество процессов, занимающихся параллельными планами, ограничено `max_parallel_workers` - 8 по умолчанию.

Ограничено количество одновременных рабочих процессов на один ведущий - `max_parallel_workers_per_gather` - 2 по умолчанию.

Нет смысла увеличивать, если нет свободных ядер в системе.

Выбор количества параллельных рабочих процессов:

* если размер таблицы меньше `min_parallel_table_scan_size` (8 МБ), планировщик не будет распараллеливать
* будет увеличивать количество процессов на каждое утроение размера таблицы (8МБ - 1 процесс, 24МБ - 2, 72МБ - 3 и т. д.)
* если для таблицы задан параметр `parallel_workers`, будет его использовать

Но во всех случаях **не превышает max_parallel_workers_per_gather** и **не выходит за общий пул max_worker_processes**

Не распараллеливаются совсем:

* запросы меняющие или блокирующие данные (INSERT, DELETE, SELECT FOR UPDATE и т. п.)
* курсоры
* функции с пометкой `PARALLEL UNSAFE`
* запросы в функциях из уже распараллеленного процесса
* запросы на уровне SERIALIZABLE

### 2.5 Примеры анализа

#### 2.5.1 Последовательное сканирование

    EXPLAIN SELECT * FROM flights;
                           QUERY PLAN                           
    ----------------------------------------------------------------
     Seq Scan on flights  (cost=0.00..4564.67 rows=214867 width=63)

Здесь `cost` - стоимость плана (первое число - стоимость подготовительного этапа, второе - общая стоимость), `rows` - оценка возвращаемого количества строк, `width` - оценка размера одной записи в байтах (не очень интересно)

Мат. модель для последовательного сканирования состоит из двух частей.

Первая - чтение страниц из памяти (стоимость чтения страницы в у.е. на количество страниц в таблице):

    SELECT relpages, current_setting('seq_page_cost'),  
        relpages * current_setting('seq_page_cost')::real AS total 
    FROM pg_class WHERE relname='flights';

        relpages | current_setting | total 
       ----------+-----------------+-------
            2416 | 1               |  2416


Вторая - обработка строк (количество строк умножается на стоимость обработки одной строки):

    SELECT reltuples, current_setting('cpu_tuple_cost'),
        reltuples * current_setting('cpu_tuple_cost')::real AS total
    FROM pg_class WHERE relname='flights';

     reltuples | current_setting |  total  
    -----------+-----------------+---------
        214867 | 0.01            | 2148.67

#### 2.5.2 Последовательное сканирование с агрегированием

    EXPLAIN SELECT count(*) FROM seats;
                          QUERY PLAN                           
    ---------------------------------------------------------------
     Aggregate  (cost=24.74..24.75 rows=1 width=8)
       ->  Seq Scan on seats  (cost=0.00..21.39 rows=1339 width=0)

Здесь у узла Aggregate есть подготовка.

Разница между стоимостью Aggregate и Sec Scan - собственно расчет количества в узле Aggregate:

    SELECT reltuples, current_setting('cpu_operator_cost'),
        reltuples * current_setting('cpu_operator_cost')::real AS total
    FROM pg_class WHERE relname='seats';

        reltuples | current_setting | total  
       -----------+-----------------+--------
            1339 | 0.0025          | 3.3475

#### 2.5.3 Параллельное последовательное сканирование

    EXPLAIN SELECT count(*) FROM bookings;
                        QUERY PLAN                              
    -------------------------------------------------------------------------
     Finalize Aggregate  (cost=25442.58..25442.59 rows=1 width=8)
     ->  Gather  (cost=25442.36..25442.57 rows=2 width=8)
       Workers Planned: 2
        ->  Partial Aggregate  (cost=24442.36..24442.37 rows=1 width=8)
         ->  Parallel Seq Scan on bookings  (cost=0.00..22243.29 rows=879629 width=0)

Эффективное количество рабочих процессов - 2.4 (2 параллельных + ведущий процесс часть работы возьмет). Отсюда количество обработанных строк:

    SELECT round(reltuples / 2.4) FROM pg_class WHERE relname = 'bookings';
      => 879629 

Оценка обработки этих строк (страницы все равно читаем полностью, но обработка делится между процессами):

    SELECT round( relpages * current_setting('seq_page_cost')::real +
        reltuples * current_setting('cpu_tuple_cost')::real / 2.4
    ) FROM pg_class WHERE relname = 'bookings';
        => 22243

Стоимость узла **Partial Aggregate** (подсчет количества):

    SELECT round(reltuples / 2.4 * current_setting('cpu_operator_cost')::real)
        FROM pg_class WHERE relname='bookings';
        => 2199

Стоимость **Gather** - это стоимость запуска рабочих процессов и получение от них данных:

    SELECT current_setting('parallel_setup_cost') parallel_setup_cost,
        current_setting('parallel_tuple_cost') parallel_tuple_cost;
         parallel_setup_cost | parallel_tuple_cost 
        ---------------------+---------------------
         1000                | 0.1




## 3. Индексное сканирование

### 3.1 Индекс B-tree

Как и любой индекс - полностью вторичная структура (не содержит никаких данных, можно удалить и заново построить)

Задача индексов:

* ускорение доступа
* поддержка ограничений целостности (первичные ключи)

Индекс - это соответствие проиндексированных полей (ключей индекса) и идентификаторов строк.

B-tree - сбалансированное дерево, глубина обычно - 4-5 уровней.

Состоит корневой, внутренних и листовых (нижних) страниц. Страницы, кроме листовых, содержат ключи и ссылки на другие страницы, где расположены те же ключи. Листовые страницы содержат ключи и ссылки на строки таблицы.

Листовые страницы соединены между собой в двунаправленный список (например можно дойти до низа дерева и перемещаться горизонтально).

Страницы могут иметь пустое место, для вставки новых ключей. Если места нет - разделяется на две. Обратно не объединяются, что ведет к разрастанию индексов

### 3.2 Index Scan

Пример индексного дерева:

                                 [1, 9]
            [1, 3, 6]                           [9, 12]
    [1, 2]   [3, 4, 5]   [6, 7, 8]       [9, 10, 11]  [12, 13, 14]

**Поиск одного значения**: например ищем строку с ключом 4: от корневого `1, 9`. 4 < 9, поэтому идем в страницу по ссылке от `3`. Из нее - на страницу по ссылке от `3`. Это листовая страница, в ней уже ссылки на строки.

Внутри страниц ключи упорядочены, поэтому обход быстро.

**Поиск по диапазону** (также по условиям больше / меньше): выбираем границу, идем по ней как в предыдущем примере. Найдя в листовой странице движемся влево / вправо по листовым страницам.

Особенности поиска: страницы таблицы читаются в произвольном порядке и могут читаться несколько раз.

### 3.3 Параллельное индексное сканирование

Ведущий процесс опускается до листовой страницы. 

Листовые страницы уже читают отдельные рабочие процессы. Они же читают и страницы таблицы при выборке строк.

При этом одну и ту же страницу таблицы могут читать разные процессы, т. к. ссылки из разных индексных страниц могут вести на одну табличную страницу.

Количество рабочих процессов - аналогичные параметры, как для последовательного: `min_parallel_index_scan_size` (512КБ) - должен спрогнозировать объем страниц индекса, `parallel_workers` (для таблицы указывается, не индекса), `max_parallel_workers_per_gather`

### 3.4 Index Only Scan

Если в индексе есть все данные, нужные для запроса (**покрывающий индекс**), к таблице можно не обращаться.

Проблема: индекс не содержит данных о видимости строк. Если страница отмечена в карте видимости (все строки актуальны) - не нужно читать табличные страницы. Поэтому очистка частая - важна.

Также можно параллельно - Parallel Index Only Scan.

### 3.5 Примеры планов

#### 3.5.1 Index Scan

    EXPLAIN SELECT * FROM bookings WHERE book_ref = 'CDE08B';
                           QUERY PLAN                                   
    ------------------------------------------------------------------
    Index Scan using bookings_pkey on bookings (cost=0.43..8.45 rows=1 width=21)
       Index Cond: (book_ref = 'CDE08B'::bpchar)

Первое число - стоимость спуска к листовому узлу. Зависит от высоты дерева.

Второе число - стоимость чтения листовых страниц и табличных страниц. Доступ случайный, 2 страницы будут прочитаны, стоимость чтения:

    SELECT current_setting('random_page_cost');
        => 4

`random_page_cost` для SSD можно снижать ближе к 1.

Если есть дополнительные условия - отображаются в блоке Filter:

    EXPLAIN SELECT * FROM bookings 
        WHERE book_ref = 'CDE08B' AND total_amount > 1000;
                            QUERY PLAN                                   
    -------------------------------------------------------------------
     Index Scan using bookings_pkey on bookings  (cost=0.43..8.45 rows=1 width=21)
       Index Cond: (book_ref = 'CDE08B'::bpchar)
       Filter: (total_amount > '1000'::numeric)

#### 3.5.2 Parallel Index Scan

Выборка четверти таблицы:

    EXPLAIN SELECT sum(total_amount) FROM bookings WHERE book_ref < '400000';
                                  QUERY PLAN                             
    ------------------------------------------------------------------------
    Finalize Aggregate  (cost=17164.90..17164.91 rows=1 width=32)
     ->  Gather  (cost=17164.67..17164.88 rows=2 width=32)
      Workers Planned: 2
       ->  Partial Aggregate  (cost=16164.67..16164.68 rows=1 width=32)
        ->  Parallel Index Scan using bookings_pkey on bookings  (cost=0.43..15604.65 rows=224008 width=6)
           Index Cond: (book_ref < '400000'::bpchar)

Стоимость **Paraller Index Scan** из двух частей.

Первая - чтение табличных страниц, аналогично последовательному параллельному:

    SELECT round( (relpages / 4.0) * current_setting('seq_page_cost')::real +
        (reltuples / 4.0) / 2.4 * current_setting('cpu_tuple_cost')::real
    ) FROM pg_class WHERE relname = 'bookings';
        => 5561

Вторая - индексный доступ (последовательный, только ведущий процесс выполняет):

    SELECT round(
        (relpages / 4.0) * current_setting('random_page_cost')::real +
        (reltuples / 4.0) * current_setting('cpu_index_tuple_cost')::real +
        (reltuples / 4.0) * current_setting('cpu_operator_cost')::real
    ) FROM pg_class WHERE relname = 'bookings_pkey';
        => 9750

#### 3.5.3 Index Only Scan

    EXPLAIN SELECT book_ref FROM bookings WHERE book_ref <= '100000';
                    QUERY PLAN                                         
    ----------------------------------------------------------------------
     Index Only Scan using bookings_pkey on bookings  (cost=0.43..4854.01 rows=139176 width=7)
        Index Cond: (book_ref <= '100000'::bpchar)

Можно посмотреть как на самом деле выполняется запрос:

    EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF)
        SELECT book_ref FROM bookings WHERE book_ref <= '100000';
                            QUERY PLAN                                  
    ------------------------------------------------------------------------
    Index Only Scan using bookings_pkey on bookings (actual rows=132109 loops=1)
    Index Cond: (book_ref <= '100000'::bpchar)
        Heap Fetches: 132109

`Heap Fetches` показывает, сколько строк выбиралось через через обращение к таблице, вместо только чтения индекса. Все строки пришлось проверять по таблице, потому что не было карты видимости. После запуска `VACUUM`, `Heap Fetches` уменьшится. 

#### 3.5.4 Index Scan и сортировка для многоколоночных индексов

Создадим индекс:

    CREATE INDEX dep_arr on flights(departure_airport, arrival_airport);

Запрос использует индексное сканирование:

    EXPLAIN SELECT * FROM flights ORDER BY departure_airport, arrival_airport;
                           QUERY PLAN                                    
    ------------------------------------------------------------------------
    Index Scan using dep_arr on flights  (cost=0.42..15199.59 rows=214867 width=63)


Но для запроса с другой сортировкой индекс не подойдет:

    EXPLAIN SELECT * FROM flights ORDER BY departure_airport, arrival_airport DESC;

    Sort  (cost=31675.96..32213.12 rows=214867 width=63)
        Sort Key: departure_airport, arrival_airport DESC
         ->  Seq Scan on flights  (cost=0.00..4564.67 rows=214867 width=63)

Нужно создавать специальный

    CREATE INDEX dep_asc_arr_desc ON flights(departure_airport, arrival_airport DESC);


## 4. Сканирование по битовой карте

### 4.1 Основы Bitmap Scan

Проблема индексного сканирования: табличные страницы читаются в произвольном порядке и по нескольку раз.

Чтение многократное: если не в кеше - нужно с диска, даже если в кеше - нужно блокировать страницу (чтобы не удалили).

Сканирование по битовой карте:

* сначала сканируется индекс **Bitmap Index Scan**, в памяти строится карта строка - страница таблицы
* затем по карте сканируется таблица **Bitmap Heap Scan**
    - страницы читаются последовательно
    - и по одному разу каждая страница

### 4.2 Использование памяти

Карта помещается в локальную память процесса. Память ограничена параметром `work_mem` (память на запрос) (4МБ). Временные файлы никогда не используются. 

Если карта не помещается в память, страницы начинают "огрублятся": биты соответствуют не отдельным строкам, а целым страницам (**lossy bitmap**). Т. о. освобождается память, но нужно перепроверять страницы, что уменьшает производительность.

Если две карты объединяются - сжатый, и у хотя бы одной фрагмент неточный, значит результирующий тоже будет неточный. 

Если битовая карта даже с ограничением не помещается в памяти - ограничение `work_mem` может нарушаться.

### 4.3 Parallel Bitmap Scan

Ведущий процесс - сканирует индекс и строит карту.

Собственно сканирование таблицы выполняют рабочие процессы параллельно.


### 4.4 Пример анализа

##### 4.4.1 Полная карта

     EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF)
        SELECT * FROM bookings WHERE total_amount < 10000;
                          QUERY PLAN                                    
    -----------------------------------------------------------
    Bitmap Heap Scan on bookings (actual rows=63944 loops=1)
        Recheck Cond: (total_amount < '10000'::numeric)
            Heap Blocks: exact=13335
       ->  Bitmap Index Scan on bookings_total_amount_idx (actual rows=63944 loops=1)
         Index Cond: (total_amount < '10000'::numeric)

Здесь `Bitmap Index Scan` - сканирование индекса и построение карты, `Bitmap Heap Scan` - чтение страниц таблицы с проверкой условия `Recheck Cond`. Но блок `Heap Blocks: exact` говорит, что дополнительная проверка не понадобилась, карта была полная.

##### 4.4.2 Неполная карта

Уменьшим рабочую память:

    SET work_mem = '64kB';

    EXPLAIN (ANALYZE, COSTS OFF, TIMING OFF)
        SELECT * FROM bookings WHERE total_amount < 10000;
                    QUERY PLAN                                    
    -------------------------------------------------------------------------
    Bitmap Heap Scan on bookings (actual rows=63944 loops=1)
      Recheck Cond: (total_amount < '10000'::numeric)
      Rows Removed by Index Recheck: 1886695
      Heap Blocks: exact=926 lossy=12409
       ->  Bitmap Index Scan on bookings_total_amount_idx (actual rows=63944 loops=1)
         Index Cond: (total_amount < '10000'::numeric)

Есть страницы с грубыми данными `Heap Blocks: lossy = 12409` и есть строки, которые были отброшены при перепроверке условия `Rows Removed by Index Recheck`

##### 4.4.3 Объединение битовых карт

    EXPLAIN (COSTS OFF) SELECT * FROM bookings
        WHERE total_amount < 10000 OR total_amount > 100000;
                          QUERY PLAN                                         
    ------------------------------------------------------
    Bitmap Heap Scan on bookings
      Recheck Cond: ((total_amount < '10000'::numeric) OR (total_amount > '100000'::numeric))
       ->  BitmapOr
         ->  Bitmap Index Scan on bookings_total_amount_idx
               Index Cond: (total_amount < '10000'::numeric)
         ->  Bitmap Index Scan on bookings_total_amount_idx
               Index Cond: (total_amount > '100000'::numeric)      

Аналогично по разным индексам может строиться

    EXPLAIN (COSTS OFF) SELECT * FROM bookings
        WHERE total_amount < 10000
        OR book_date = bookings.now() - INTERVAL '1 day';

##### 4.4.4 Кластеризация

При кластеризации строки в таблице упорядочиваются в порядке указанного индекса. Тогда можно не строить битовую карту.

Но:

* кластеризация на момент построения полностью блокирует таблицу
* после построения кластеризация не поддерживается: изменения таблицы будут ухудшать кластеризацию.

Создаем кластер:

    CLUSTER bookings USING bookings_total_amount_idx;

Теперь без использования битовых карт запрос:

    EXPLAIN SELECT * FROM bookings WHERE total_amount < 10000;
                        QUERY PLAN                                            
    ----------------------------------------------------------------
    Index Scan using bookings_total_amount_idx on bookings  (cost=0.43..2372.66 rows=67899 width=21)
        Index Cond: (total_amount < '10000'::numeric)


### 4.5 Сравнение способов доступа

Индексное сканирование: когда высокая селективность, мало строк выбирается.

Сканироване по битовой карте - лучше индексного, т. к. нет повторного чтения страниц. При средней селективности хорошо работает. Из-за накладных расходов проигрывает индексному при высокой селективности.

Последовательное сканирование выигрывает при низкой селективности, когда другие способы начинают проигрывать из-за накладных расходов. Особенно заметно на HDD из-за разницы последовательного и произвольного доступа.

Индексное сканирование дает сразу отсортированный результат, это может повышать его привлекательность для планировщика.

Также если строки в таблице физически упорядочены (кластеризация), индексный доступ лучше доступа по битовой карте (нет повторного чтения страниц)

Исключительно индексное сканирование зависит от состояния карты видимости. При плохих прогнозах будет применяться обычное индексное



## 5. Соединение вложенным циклом

### 5.1 Общие замечания

`LEFT, INNER, FULL, CROSS JOIN` и др. - это логические операции.

Способы соединения - это то как они реализованы.

Соединяются не таблицы, а наборы строк. Наборы строк могут быть получены из любого узла плана.

Наборы строк соединяются попарно. С точки зрения логики не важно в каком порядке соединяются, но важно с точки зрения производительности (`a join b` или `b join a`).

### 5.2 Соединение вложенным циклом (Nested Loop)

Для каждой строки одного набора перебираем все строки другого набора и возвращаем строки при выполнении условия.

Сложность такого алгоритма - **M x N**, `M, N` - количество строк в наборах.

Хорошо бы иметь быстрый доступ к строкам внутреннего набора, например индексный доступ для поля, которое входит в условие соединения.

Подготовка минимальна, может сразу возвращать данные, как только найдено совпадение.

Распараллеливается: внешний набор читается несколькими процессами. Получив внешнюю строку, процесс просматривает целиком внутренний набор.

Крайне неэффективен при больших объемах. Подходит для OLTP-запросов в сочетании с индексным доступом, когда надо быстро вернуть небольшое количество строк.

Работает с любыми условиями соединения (не только равенство / неравенство)

### 5.3 Пример анализа

    EXPLAIN SELECT *
      FROM tickets t JOIN ticket_flights tf ON tf.ticket_no = t.ticket_no 
      WHERE t.ticket_no IN ('0005432312163','0005432312164');
                 QUERY PLAN                                              
    ---------------------------------------------------------------------------
    Nested Loop  (cost=0.99..46.09 rows=6 width=136)
     -> Index Scan using tickets_pkey on tickets t  (cost=0.43..12.89 rows=2 width=104)
      Index Cond: (ticket_no = ANY ('{0005432312163,0005432312164}'::bpchar[]))
     -> Index Scan using ticket_flights_pkey on ticket_flights tf  (cost=0.56..16.57 rows=3 width=32)
      Index Cond: (ticket_no = t.ticket_no)

Здесь первый узел - внешний цикл, второй - внутренний.

Порядок что внешним набором будет, что внутренним - определяется планировщиком, а не как записан запрос. Аналогично для правых, левых соединений.

**Первая компонента** стоимости узла `Nested Loop` - сумма первых компонентов дочерних.

**Вторая компонента**:

* стоимость получения строк внешнего набора 
* стоимость получения строк внутреннего набора, умноженная на количество строк внешнего
* стоимость обработки строк

Есть разные модификации узла: `Nested Loop Left Join`, `Nested Loop Anti Join
`. 

В качестве внутренних узлов могут быть любые комбинации `Seq Scan`, `Index Scan`, `Bitmap Scan`.





## 6. Соединение хешированием (Hash Join)

### 6.1 Алгоритм соединения

**Первым этапом** строится хеш-таблица в памяти. Значения равномерно распределяются по нескольким корзинам (пакетам?). Хеш строится от полей, входящих в условие соединения.

В корзину помещается хеш и все поля, участвующие в соединении или нужные для запроса (поэтому `SELECT *` - не очень). 

Размер в памяти ограничен `work_mem`. Хорошо, когда вся таблица помещается.

**Вторым этапом** читается второй набор. Вычисляется хеш от полей условия для строки. В хеш-таблице ищется по хешу строка первого набора и проверяется условие (одного хеша мало - коллизии). Допустимые условия соединения - равно / не равно.

Сложность алгоритма - `M + N`. Есть накладные расходы, не сразу готов отдавать результат. На больших данных эффективней, чем вложенный цикл.

Параллельный режим с версии 9.6:

* каждый рабочий процесс строит свою хеш-таблицу. Чтение первого набора за счет буферного кольца эффективно.
* рабочие процессы делят второй набор и обрабатывают параллельно его

Начиная с версии 11 - уже и общую хеш-таблицу параллельно строят

В условиях соединения допустимо только равно / не равно.

Хеширование также применяется для группировок и получения различных значений:

    EXPLAIN SELECT fare_conditions, count(*) FROM seats GROUP BY fare_conditions;
                    QUERY PLAN                           
    ------------------------------------------------------------
    HashAggregate  (cost=28.09..28.12 rows=3 width=16)
      Group Key: fare_conditions
       ->  Seq Scan on seats  (cost=0.00..21.39 rows=1339 width=8)



### 6.2 Использование памяти

Память операции ограничена параметром `work_mem` (не жесткое, может превышать). Параметр задает количество памяти для операций сортировки, хеширования. Таких операций в одном запросе может быть несколько. На каждую - свой объем памяти.

Если памяти не хватает - используется дисковое пространство. Также ограничено `temp_file_limit` (без учета временных таблиц), но уже на весь сеанс.

Первый набор делится на пакеты, приблизительно одинаковое количество строк в пакете, так, чтобы хеш-таблица пакета целиком попадала в память.  Если оптимизатор ошибся с количеством пакетов - может увеличиваться. Если все равно превышает `work_mem`, значит будет превышать.

Для первого пакета строится хеш-таблица в памяти. Остальные пакеты сбрасываются на диск, каждый в свой файл. Затем выполняет обход второго набора. Если строка относится к первому пакету (похоже по младшим битам хеша распределяются), значит выполняется поиск по хешу и проверка условия. Если другой пакет - сбрасывается на диск также по пакетам.

Т. о. на диске может находится 2 * (N - 1) файлов, где N - количество пакетов.

Затем пакеты попарно извлекаются с диска и соединяются.

Для эффективности нужно, чтобы пакетов было меньше, т. е. хеш-таблица попадала в память: строить хеш таблицу по меньшему набору строк и минимум полей в условиях соединения и выбираемых полей.

### 6.3 Пример анализа

#### 6.3.1 Простой пример

    EXPLAIN SELECT * FROM tickets t JOIN ticket_flights tf 
        ON tf.ticket_no = t.ticket_no;
                  QUERY PLAN                                     
        ----------------------------------------------------------------------
    Hash Join  (cost=161241.33..494089.17 rows=8391906 width=136)
     Hash Cond: (tf.ticket_no = t.ticket_no)
      ->  Seq Scan on ticket_flights tf  (cost=0.00..149997.06 rows=8391906 width=32)
      ->  Hash  (cost=78283.70..78283.70 rows=2949570 width=104)
        ->  Seq Scan on tickets t  (cost=0.00..78283.70 rows=2949570 width=104)

Здесь `Hash Join` включает два узла: сначала `Hash` строит хеш-таблицу из данных `Seq Scan`, затем обход второй таблицы через `Seq Scan`

Первая компонента стоимости: стоимость получения всего первого набора данных + стоимость создания хеш-таблицы.

Вторая компонента: стоимость получения второго набора + стоимость соединения + стоимость чтения с диска, если предполагается больше 1-го пакета.

#### 6.3.2 Пример использования временных файлов

    EXPLAIN (COSTS OFF, TIMING OFF, ANALYZE) SELECT *
        FROM bookings b JOIN tickets t ON b.book_ref = t.book_ref;
                    QUERY PLAN                            
    ------------------------------------------------------------------
    Hash Join (actual rows=2949857 loops=1)
     Hash Cond: (t.book_ref = b.book_ref)
     ->  Seq Scan on tickets t (actual rows=2949857 loops=1)
       ->  Hash (actual rows=2111110 loops=1)
          Buckets: 4194304  Batches: 1  Memory Usage: 104862kB
         ->  Seq Scan on bookings b (actual rows=2111110 loops=1)
 
Здесь Buckets - число корзин, Batches - число пакетов (1 пакет - т. е. поместился в память)

Теперь уменьшаем память и включаем вывод о записи врем. файлов в логи

    SET work_mem = '2MB';
    SET log_temp_files = 0;

    EXPLAIN (COSTS OFF, ANALYZE, TIMING OFF) SELECT b.book_ref
        FROM bookings b JOIN tickets t ON b.book_ref = t.book_ref;
                            QUERY PLAN                            
    ------------------------------------------------------------------
    Hash Join (actual rows=2949857 loops=1)
      Hash Cond: (t.book_ref = b.book_ref)
       ->  Seq Scan on tickets t (actual rows=2949857 loops=1)
       ->  Hash (actual rows=2111110 loops=1)
         Buckets: 1048576  Batches: 4  Memory Usage: 18011kB
         ->  Seq Scan on bookings b (actual rows=2111110 loops=1)

Здесь уже пакетов больше одного. В логах - временные файлы ((4 - 1) * 2 = 6 шт):

    tail -n 18 /var/log/postgresql/postgresql-10-main.log

Также можно посмотреть с параметром BUFFERS:

    EXPLAIN (BUFFERS) SELECT ...

Hash: `temp written` - страницы пакетов, записанные при построении хеш-таблицы;
Hash Join: `temp read/written` - чтение и запись временных файлов на этапе соединения.

## 7. Соединение слиянием

### 7.1 Алгоритм

Оба набора должны быть отсортированы предварительно. Если через индексный доступ - уже отсортированы, иначе - сортировка в памяти `work_mem`.

Далее попарно сравниваем строки. Курсор перемещается в том наборе, в котором текущее поле меньше. Полученный набор также является отсортированным, что хорошо, если вышестоящим узлам нужно.

Сложность: `M + N`, если нужна еще и сортировка предварительная, тогда + `NlogN + MlogM`.

Эффективно на больших наборах, в отличие от хеширования - не нужна дополнительная память для хеш-таблицы.

В параллельном режиме: рабочие процессы параллельно читают один набор строк, но второй набор каждый процесс читает самостоятельно. Результаты объединяются специальным узлом `Gather Merge`, чтобы сохранить сортировку

### 7.2 Использование памяти (для сортировки)

В идеальном случае весь набор помещается в память `work_mem`, сортируется и возвращается результат.

Если не помещается - алгоритм внешней сортировки.

Строки читаются в память, пока есть место, сортируются и сбрасываются на диск. Получается несколько отсортированный файлов. Затем файлы соединяются слиянием.

Если не хватает памяти, часть файлов соединяются, сбрасываются на диск и заново укрупненные соединяются.

При ограниченной памяти внешняя сортировка эффективнее, чем хеширование через временные файлы. Поэтому при ограаниченной памяти будет применять соединение слиянием. При увеличении памяти будет переключаться на слияние через хеш-таблицу

### 7.3 Построение B-tree индекса

Все строки сортируются, затем раскладываются по листовым страницам. Затем достраиваются страницы следующего верхнего уровня со ссылками на нижние страницы и так далее, пока не останется одна корневая страница.

Сортировка по тому же принципу работает, с использованием временных файлов, но объем памяти - `maintenance_work_mem` 

### 7.4 Пример

#### 7.4.1 Простое соединение слиянием

     EXPLAIN SELECT * FROM tickets t 
     JOIN ticket_flights tf ON tf.ticket_no = t.ticket_no ORDER BY t.ticket_no;
         QUERY PLAN                                                   
    -------------------------------------------------------------------
    Merge Join  (cost=38.10..787871.36 rows=8391906 width=150)
     Merge Cond: (t.ticket_no = tf.ticket_no)
      ->  Index Scan using tickets_pkey on tickets t  (cost=0.43..138478.98 rows=2949570 width=104)
      ->  Index Scan using ticket_flights_pkey on ticket_flights tf  (cost=0.56..537184.08 rows=8391906 width=32)

Первая компонента:

* сумма первых компонентов дочерних узлов (сортировка в т. ч., если нужна)
* стоимость получения первой пары строк

Вторая компонента: 

* суммы стоимостей дочерних узлов 
* стоимость сравнения наборов

Хорошо подходит,  если есть ограничение на количество строк (`LIMIT`) (в отличии от хеширования не нужно строить таблицу по всему набору)

#### 7.4.2 Сортировка для уникальных значений и группировки

    EXPLAIN SELECT DISTINCT book_date FROM bookings ORDER BY book_date;
                                  QUERY PLAN                                  
    --------------------------------------------------------------------------
    Unique  (cost=314054.67..324610.22 rows=441843 width=8)
      -> Sort  (cost=314054.67..319332.45 rows=2111110 width=8)
         Sort Key: book_date
         ->  Seq Scan on bookings  (cost=0.00..34558.10 rows=2111110 width=8)


## 8. Статистика

### 8.1 Базовая статистика

Статистика в **pg_class**: 

* `reltuples` - число строк в таблице / индексе
* `relpages` - число страниц в таблице / индексе

Статистика в **pg_statistic** (и представление  **pg_stat**)

* `null_frac` - доля `null` в столбце (0..1)
* `n_distinct` - количество уникальных значений в столбце. Если отрицательное - доля уникальных значений
* `most_common_values` - массив наиболее частых значений
* `most_common_freqs` - массив частот наиболее частых значений

Если нужно оценить кардинальность по условию `WHERE a = ...`, смотрим среди частот, если `WHERE a < ..` или `WHERE a > ...` - суммируем частоты.

Максимальное количество элементов в массиве наиболее частых - `default_statistics_target` (100 по умолчанию)

### 8.2 Гистограмма

Если различных значений слишком много.

Гистограмма - набор корзин (количество ограничено `default_statistics_target`). Ширина корзин подбирается, чтобы одинаковое количество значений в них было (площадь на графике одинаковая).

Хранятся только крайние значения корзин. Частота одной корзины - 1 / число корзин.

Оценка кардинальности для `WHERE a < ..` - (число корзин слева от а) / общее число корзин. Оценка для условия на равенство - не поддерживается, приходится через 1 / `n_distinct`.

Обычно - комбинация методов: наиболее частые значения + гистограмма.


### 8.3 Дополнительные поля

`correlation` - степень упорядоченности данных на диске. 1 - данные хранятся по возрастанию, -1 - по убыванию, около 0 - хаотично. Используется оптимизатором для решения: битовая карта или обычное индексное сканирование

`relallvisible` - количество страниц с только актуальными строками (обновляется при изменении карты видимости). Для решения: исключительно индексное сканирование или по битовой карте.

`avg_width` - средний размер строки в байтах, для оценки памяти

### 8.4 Расширенная статистика

Начиная с Postgres 10 можно создавать статистику по нескольких столбцам таблицы. Хранится в **pg_statistic_ext**

Статистика по зависимости между двумя столбцами. Например столбцы сильно связаны, один столбец определяет значение в другом столбце. В обычных условиях планировщик будет занижать кардинальность, если условия накладываются на оба столбца, считая что каждое условие снижает количество строк.

Статистика по числу уникальных значений в нескольких столбцах. Используется в группировках.

Например так создать статистику для двух колонок:

    CREATE STATISTICS flights1(dependencies)
        ON flight_no, departure_airport FROM flights;
    ANALYZE

### 8.5 Как выполняется сбор статистики

Статистика для **pg_class** (reltuples, relpages) собирается некоторыми DDL операциями (`CREATE INDEX`, `CREATE TABLE AS SELECT`), при очистке и анализе.

Планировщик уточняет значения в зависимости от физического размера таблиц.

Остальная статистика собирается очисткой и анализом (`VACUUM`, `ANALYZE`).

При сборе - случайная выборка. Выбирается 300 * `default_statistics_target`.

[как используется статистика](https://postgrespro.ru/docs/postgresql/10/row-estimation-examples)


## 9. Профилирование

### 9.1 Общие подходы

Начало:

* разбить задачу на подзадачи
* измерить долю времени и количество выполнений для каждой подзадачи

Оптимизировать: 

* наиболее длительную подзадачу
* или уменьшить количество часто выполняемых

Что измерять:

* время - как наиболее понятная и простая. Но сильно зависит от текущей нагрузки, кеширования т. п.
* количество ввода / вывода (страниц обычно)

Смотреть профиль можно в общем или детально. Лучше детально (отсекая другие запросы в БД, не связанные с проблемой), хотяя общий взгляд может выявить и другие проблемы.

Можно измерять общее время отклика и отдельно время отклика БД, тогда будет понятно, что проблема именно в БД


### 9.2 Профилирование запросов

Для профилирования функций на **PL/pgSQL** - расширение **PL Profiler**.

**Первый способ**: логи

Задаем `log_min_duration_statement` и видим в логах все запросы, время которых превышает указанное. Можно другие параметры посмотреть.

Через `log_line_prefix` можно настроить метаинформацию сообщения в логах 

Анализ вложенных запросов - расширение **auto_explain**.

Анализ логов - **pgBadger**

**Второй способ** - расширение **pg_stat_statements**

Собирает статистику по запросам, в т. ч. ввод/вывод. Хранит в `pg_stat_statements`.

Размер хранилища ограничен параметром, поэтому отображаются наиболее частые. Хранит запросы с точностью до констант, хотя разные значения могут давать разные планы. 

Запросы относятся к пользователю, базе данных, но нельзя по сеансу определить.

    # устанавливаем расширение
    CREATE EXTENSION pg_stat_statements;
    # подключаем библиотеку
    ALTER SYSTEM SET shared_preload_libraries = 'pg_stat_statements';
    # перезагрузка нужна

### 9.3 Профилирование одного запроса

Команда `EXPLAIN ANALYZE`

Что смотреть:

* `actual time` - время выполнения
* `loops` - число выполнений
* `BUFFERS` - объем ввода вывода. Можно оценить число страниц в таблицах (через pg_class.relpages), чтобы посмотреть не читается ли что-то лишнее.
* отличия в ожидаемом количестве строк и реальном (порядок и больше) узлах. 
* сколько строк выбирается и способ (мало и последовательное сканирование наприер)

Иногда слишком долго может выполняться, тогда только `EXPLAIN`

## 10 Приемы оптимизации

### 10.1 Оптимизация параметрами

#### 10.2.0 Пути оптимизации

Цель оптимизации - получить адекватный план выполнения запроса.

Варианты:

* Исправить планировщик, указать как строить план (hints), Postgres не поддерживает такое
* Добиваться правильной оценки кардинальности в узлах плана

Если все равно не устраивает - настройка *глобальных* параметров (например стоимость отдельных операций)


#### 10.2.1 Оптимизация через статистику

Статистика должна собираться регулярно и часто.

Точной абсолютно не будет, но не должно быть больших расхождений в оценке кардинальности в узлах плана.

Повысить точность статистики:

* увеличить `default_statistics_target`
* построить статистику по выражению
* использовать расширенную статистику для коррелированных колонок

Повысить эффективность использования имеющейся статистики:

* переформулировать запрос (не всегда планировщик может оценить сложные соединения например)
* поместить часть запроса во временную таблицу (сможет оценить кардинальность этого узла, но это накладные расходы)

#### 10.2.2 Оптимизация через настройку стоимости операций

Имеет смысл изменять, если планировщик верно вычислил кардинальность, но подобран не эффективный план.

Ввод-вывод:

* `seq_page_cost` = 1
* `random_page_cost`= 4. Для SSD есть смысл опускать ближе к 1. Влияет на выбор между индексным сканированием и битовой картой.
* `effective_io_concurrency` = 1. Можно повышать, если дисковый массив.

Время процессора:

* `cpu_tuple_cost` = 0.01
* `cpu_index_tuple_cost` = 0.005
* `cpu_operator_cost` = 0.0025
* `CREATE FUNCTION .. COST ..`

Здесь вряд ли что-то стоит менять. Можно только задавать стоимость функций. Когда функции используются в условиях `WHERE f() > .. AND g() < ..`, функция с меньшей стоимостью вычисляется первой, если ложно - вторая может совсем не выполнятся.

Для курсоров есть параметр `cursor_tuple_fraction` = 0.1. Если нужен быстрый результат - можно уменьшать его.

#### 10.2.3 Настройки параметров процессов

Используемая память:

* `work_mem` = 4МБ. Количество памяти на операцию (сортировку, хеширование и т. п.). Следует увеличивать. Недостаток памяти - использование временных файлов, слияние сортировкой вместо хеширования
* `maintenance_work_mem` = 64МБ - служебные процессы: очистка, индексы и т. п.
* `effective_cache_size` = 4 ГБ. Критерий для использования индексного доступа: чем выше, тем более предпочтителен (много кеша, произвольный доступ к индексу дешевле), ни к чему не привязан физически.

#### 10.2.4 Настройка построения планов

* `join_collapse_limit` = 8. Максимальное количество соединений, для которого планировщик пытается подобрать порядок соединения
* `from_collapse_limit` = 8. Аналогично для подзапросов в секции `FROM`
* `geqo_threshold` = 12. Число соединений, после которого переключается на генетический алгоритм.

Увеличение этих параметров позволит подобрать более оптимальный план, но требует затрат на планирование. 

Есть смысл увеличивать, когда выполняются сложные тяжелые запросы.

#### 10.2.5 Способы задания параметров

Ложализация:

* на уровне всей системы
* на уровне базы данных
* на уровне табличных пространств
* на уровне роли
* локально в сеансе
* локально в транзакции

#### 10.2.6 Отладочные параметры

Указание планировщику использовать / не использовать определенные способы выполнения:

`enable_seqscan`, `enable_nestloop` и т. п.

`force_parallel_mode`

### 10.3 Оптимизация на уровне схемы БД

#### 10.3.1 Нормализация / денормализация

С логической точки зрения база должна быть нормализованной: в данных не должно быть избыточности (упрощается поддержка, работа и т. п.)

С другой стороны денормализация может дать выигрыш в производительности. За денормализацию приходится платить: поддержка согласованности, синхронизация с основными данными и т. п.

Примеры денормализации:

* индексы (автоматическая поддержка согласованности)
* предрассчитанные поля (триггеры обычно используются)
* материализованные представления (надо обновлять, по расписанию может быть)
* кеширование на уровне приложения

#### 10.3.2 Типы данных и ограничения

Выбор определенного типа может повысить производительность.

Например:

* использование диапазона дат `daterange` вместо отдельных колонок за счет особых индексов может уксорить операции связанные с пересечением
* составные типы (массивы, JSON) вместо отдельных таблиц - экономия места (за счет заголовков строк) и экономия на соединениях

Ограничения целостности могут учитываться планировщиком:

* Первичный ключ или уникальность: построение индекса, уникальность упрощает соединения.
* Внешний ключ и NOT NULL также упрощает соединение и улучшает оценку селективности

#### 10.3.3 Физическое расположение

Табличные пространства: для разнесения разных таблиц на разные физические устройства.

Секционирование: для работы с большими объемами данных



### 10.4 Переформулирование запроса

Можно заставить планировщик выполнять соединения в указанном порядке:

* через подзапросы CTE (всегда материализуются, помещаются в память (`work_mem`) или временные файлы)
* установить `join_collapse_limit` = 1
* аналогично для подзапросов `from_collapse_limit`

Переписать запрос:

* не может преобразовывать условие OR в соединение таблиц
* также коррелированные запросы сам не может в соединения


Заменить множественный вызов мелких запросов одним общим